{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"neural_network.py","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPXtBUYLTH1haqSoRlt7xUs"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"4eUs2BtOCY1t","colab_type":"text"},"source":["precision: devuelve (el número o porcentaje) de muestras clasificadas correctamente El mejor, rendimiento es 1\n","\n","exactitud_ accuracy:\n","exhautividad:\n","\n","re.call: la relación entre la cantidad de (verdaderos positivos y el número de falsos negativos). El recuerdo es intuitivamente la capacidad del clasificador para encontrar todas las muestras positivas.\n","\n","f1-score: Un promedio ponderado de la precisión y recall"]},{"cell_type":"code","metadata":{"id":"4TQPZGnuBVAB","colab_type":"code","outputId":"a651714e-881e-420f-eb58-987032daf763","executionInfo":{"status":"ok","timestamp":1583770349781,"user_tz":300,"elapsed":2154,"user":{"displayName":"catalina preciado","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg2qE_ggbA4MmQJ0PWkJVOSCDPIP94QbDyaB1b_=s64","userId":"17690235812653628551"}},"colab":{"base_uri":"https://localhost:8080/","height":408}},"source":["import sklearn\n"," \n","## import the iris dataset for classification\n"," \n","from sklearn import datasets\n","iris=sklearn.datasets.load_iris()\n"," \n","## print some data, to see the imported dataset\n"," \n","print(\"Printing some sample data from the iris dataset\")\n","for training_sample in list(zip(iris.data,iris.target))[:5]:\n","    print(training_sample)\n"," \n","## save the features and class\n"," \n","features=iris.data   # split iris dataset into features and iris_class\n","iris_class=iris.target  # class[X] is output corresponding to features[X]\n"," \n","## Split the dataset into training (70%) and testing (30%)\n","## Note that the shuffle parameter has been used in splitting.\n"," \n","print(\"Splitting the data into testing and training samples\")\n","from sklearn.model_selection import train_test_split\n","features_train, features_test,iris_class_train, iris_class_test = train_test_split(features,iris_class, test_size=0.33, random_state=42)\n"," \n","## data preprocessing: Before training the network we must scale the feature data\n","print(\"Data preprocessing\")\n","from sklearn.preprocessing import StandardScaler\n","scaler = StandardScaler()\n","scaler.fit(features_train)\n","features_train_scale = scaler.transform(features_train)\n","features_test_scale = scaler.transform(features_test)\n"," \n","## The MLPClassifier and MLPRegressor are sklearn implementations of NNs\n"," \n","from sklearn.neural_network import MLPClassifier\n","iterations=1000   # define the iterations for training over the dataset\n","hidden_layers=[10,10,10]  # define the layers/depth of the NN\n"," \n","mlp = MLPClassifier(hidden_layer_sizes=(hidden_layers), max_iter=iterations) \n"," \n","# an object which represents the neural network\n","# Remember to use the pre-processed data and not original values for fit()\n"," \n","mlp.fit(features_train_scale, iris_class_train)  # fit features over NN\n"," \n","## Run the test data over the network to see the predicted outcomes.\n"," \n","predicted = mlp.predict(features_test_scale)  \n"," \n","# predict over test data\n","## evaluation metrics and analysing the accuracy/output.\n","print(\"Evaluation: considering the confusion matrix\")\n","from sklearn.metrics import confusion_matrix\n","print(confusion_matrix(iris_class_test,predicted))  \n","# all non-diagonal elements are 0 if you get 100% accuracy\n"," \n","print(\"Evaluation report:\")\n","from sklearn.metrics import classification_report\n","print(classification_report(iris_class_test,predicted)) \n","#precision: clasifico bien los todos los elementos 0 y 2, fallando una vez clasificando el elemento 1\n","#recall: en el elemento 2 no reconocio una muestra (lo tomo como un verdadero falso)\n","#f1_score: "],"execution_count":0,"outputs":[{"output_type":"stream","text":["Printing some sample data from the iris dataset\n","(array([5.1, 3.5, 1.4, 0.2]), 0)\n","(array([4.9, 3. , 1.4, 0.2]), 0)\n","(array([4.7, 3.2, 1.3, 0.2]), 0)\n","(array([4.6, 3.1, 1.5, 0.2]), 0)\n","(array([5. , 3.6, 1.4, 0.2]), 0)\n","Splitting the data into testing and training samples\n","Data preprocessing\n","Evaluation: considering the confusion matrix\n","[[19  0  0]\n"," [ 0 15  0]\n"," [ 0  1 15]]\n","Evaluation report:\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        19\n","           1       0.94      1.00      0.97        15\n","           2       1.00      0.94      0.97        16\n","\n","    accuracy                           0.98        50\n","   macro avg       0.98      0.98      0.98        50\n","weighted avg       0.98      0.98      0.98        50\n","\n"],"name":"stdout"}]}]}